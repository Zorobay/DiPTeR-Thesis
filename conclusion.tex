In this thesis we developed a specialized framework for both differentiable procedural texture rendering using PyTorch in Python and conventional procedural texture rendering using OpenGL. The back-end PyTorch renderer was implemented to mimic the results of the user-facing OpenGL renderer so that results from parameter estimation using gradient descent on our back-end differentiable renderer would be valid and correct in OpenGL as well. Our framework supports dynamic creation of procedural texture models at runtime using a graphical node editor interface. As OpenGL does not support shader composition, we implemented a GLSL code parser that breaks down the source code into Python objects that can be reassembled and recompiled at runtime as the user designs a procedural texture model. Finally, we designed three different test models to evaluate our system and several textures for each model to serve as targets for parameter estimation. Each shader was evaluated with a combination of different loss functions, optimizers and target textures.

We found that by using an automatic differentiation framework like PyTorch it was possible to implement a fully differentiable texture renderer. However, as PyTorch is not optimized for computer graphics it was only usable for real time rendering for very low resolutions when using more complex texture models. Real time rendering performance was never needed though, as we could restrict the use of the differentiable renderer to parameter estimation by mimicking the rendering process in OpenGL to a high degree by adapting our Python syntax to that of GLSL.

Through evaluation we learned that our system could, in many cases, find a more optimal parameter set that faithfully restored colors and scale but not elongation of our brick textures. As noise is innately very volatile it was also difficult to optimize and we rarely saw any change in noise parameters during parameter estimation. For simple optimization problems \dipter{} required fewer than 10 iterations, taking only a few seconds in total to execute. However, for more complex models, especially when using a neural loss, a few hundred iterations were needed where each iteration took over a second to perform. \hl{This is comparable to the results of Guo et. al. where a model with $23$ parameters (similar to our $M_3$) is optimized, also using PyTorch, in $290$ seconds over $1000$ iterations, although they tested on much newer hardware and could thus utilize GPU acceleration} \cite{guo_2019_a}.

We evaluated two optimizers, Adam and RMSprop, which in many cases performed comparatively well although Adam tended to find a lower loss while RMSprop tended to optimize more efficiently. Overall, RMSprop performed slightly better for simpler shader models and loss functions while using Adam proved advantageous when using the neural loss function on targets with a significant amount of noise. Using the neural loss function proved a necessity for our most complex shader model $M_3$ and overall produced the most accurate results, but required a significant amount of experimentation with its settings to work well. Ultimately, using gradient descent to estimate parameters in a differentiable rendering framework proved a flexible and fairly simple method for dynamically created procedural textures. The biggest drawbacks being that it needs a custom built rendering framework and the accuracy of the result relies heavily on a correctly tuned loss function and could benefit from an implementation more optimized for computer graphics.


\section{Future Work}

Our differentiable renderer is a highly specialized and simplified version of OpenGL, developed exclusively for 2D rendering of procedural textures. As explained, it is not optimized for computer graphics and although our rendering evaluation is performed on fairly old hardware without GPU acceleration support, thus missing out on a significant amount of performance potential, even better results can be obtained by using a more optimized tool. The team behind PyTorch are currently working on a dedicated general differentiable renderer named PyTorch3D which should bring useful features and a needed performance boost if implemented in our project \cite{facebookresearch_2020_facebookresearchpytorch3d}. If such a system performs well enough, exclusively using it for rendering would eliminate any problems with discrepancies between our two current systems but would also forego the exportability that comes with using OpenGL shaders.

In section \ref{sec:EvalParameterEstimation} we evaluated three different shader models on a sizeable number of combinations of loss functions, optimizers and targets. However, we only had enough time to implement and test shaders that produce brick textures of varying complexity which have a rather specific uniform pattern. In the future, more types of shaders should be tested with different and more irregular patterns. We also found that while the neural loss function gave the best results in most cases, it requires a good amount of adjustment of its \texttt{layers} and \texttt{weights} parameters to perform well. A look into alternative loss functions or more research on neural loss functions is needed.
